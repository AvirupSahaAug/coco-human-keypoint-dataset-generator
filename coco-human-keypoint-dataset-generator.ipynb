{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion,\n                                  momentum=BN_MOMENTUM)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck_CAFFE(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck_CAFFE, self).__init__()\n        # add stride to conv1x1\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion,\n                                  momentum=BN_MOMENTUM)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass PoseResNet(nn.Module):\n\n    def __init__(self, block, layers):\n        self.inplanes = 64\n        self.deconv_with_bias = False\n\n        super(PoseResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n\n        # used for deconv layers\n        self.deconv_layers = self._make_deconv_layer(\n            3,\n            [256, 256, 256],\n            [4, 4, 4],\n        )\n\n        self.final_layer = nn.Conv2d(\n            in_channels=extra.NUM_DECONV_FILTERS[-1],\n            out_channels=17,\n            kernel_size=1,\n            stride=1,\n            padding=1 \n        )\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def _get_deconv_cfg(self, deconv_kernel, index):\n        if deconv_kernel == 4:\n            padding = 1\n            output_padding = 0\n        elif deconv_kernel == 3:\n            padding = 1\n            output_padding = 1\n        elif deconv_kernel == 2:\n            padding = 0\n            output_padding = 0\n\n        return deconv_kernel, padding, output_padding\n\n    def _make_deconv_layer(self, num_layers, num_filters, num_kernels):\n        assert num_layers == len(num_filters), \\\n            'ERROR: num_deconv_layers is different len(num_deconv_filters)'\n        assert num_layers == len(num_kernels), \\\n            'ERROR: num_deconv_layers is different len(num_deconv_filters)'\n\n        layers = []\n        for i in range(num_layers):\n            kernel, padding, output_padding = \\\n                self._get_deconv_cfg(num_kernels[i], i)\n\n            planes = num_filters[i]\n            layers.append(\n                nn.ConvTranspose2d(\n                    in_channels=self.inplanes,\n                    out_channels=planes,\n                    kernel_size=kernel,\n                    stride=2,\n                    padding=padding,\n                    output_padding=output_padding,\n                    bias=self.deconv_with_bias))\n            layers.append(nn.BatchNorm2d(planes, momentum=BN_MOMENTUM))\n            layers.append(nn.ReLU(inplace=True))\n            self.inplanes = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.deconv_layers(x)\n        x = self.final_layer(x)\n\n        return x\n\n    def init_weights(self, pretrained=''):\n        if os.path.isfile(pretrained):\n            logger.info('=> init deconv weights from normal distribution')\n            for name, m in self.deconv_layers.named_modules():\n                if isinstance(m, nn.ConvTranspose2d):\n                    logger.info('=> init {}.weight as normal(0, 0.001)'.format(name))\n                    logger.info('=> init {}.bias as 0'.format(name))\n                    nn.init.normal_(m.weight, std=0.001)\n                    if self.deconv_with_bias:\n                        nn.init.constant_(m.bias, 0)\n                elif isinstance(m, nn.BatchNorm2d):\n                    logger.info('=> init {}.weight as 1'.format(name))\n                    logger.info('=> init {}.bias as 0'.format(name))\n                    nn.init.constant_(m.weight, 1)\n                    nn.init.constant_(m.bias, 0)\n            logger.info('=> init final conv weights from normal distribution')\n            for m in self.final_layer.modules():\n                if isinstance(m, nn.Conv2d):\n                    # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                    logger.info('=> init {}.weight as normal(0, 0.001)'.format(name))\n                    logger.info('=> init {}.bias as 0'.format(name))\n                    nn.init.normal_(m.weight, std=0.001)\n                    nn.init.constant_(m.bias, 0)\n\n            # pretrained_state_dict = torch.load(pretrained)\n            logger.info('=> loading pretrained model {}'.format(pretrained))\n            # self.load_state_dict(pretrained_state_dict, strict=False)\n            checkpoint = torch.load(pretrained)\n            if isinstance(checkpoint, OrderedDict):\n                state_dict = checkpoint\n            elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n                state_dict_old = checkpoint['state_dict']\n                state_dict = OrderedDict()\n                # delete 'module.' because it is saved from DataParallel module\n                for key in state_dict_old.keys():\n                    if key.startswith('module.'):\n                        # state_dict[key[7:]] = state_dict[key]\n                        # state_dict.pop(key)\n                        state_dict[key[7:]] = state_dict_old[key]\n                    else:\n                        state_dict[key] = state_dict_old[key]\n            else:\n                raise RuntimeError(\n                    'No state_dict found in checkpoint file {}'.format(pretrained))\n            self.load_state_dict(state_dict, strict=False)\n        else:\n            logger.error('=> imagenet pretrained model dose not exist')\n            logger.error('=> please download it first')\n            raise ValueError('imagenet pretrained model does not exist')\n\n\nresnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),\n               34: (BasicBlock, [3, 4, 6, 3]),\n               50: (Bottleneck, [3, 4, 6, 3]),\n               101: (Bottleneck, [3, 4, 23, 3]),\n               152: (Bottleneck, [3, 8, 36, 3])}\n\n\nmodel = PoseResNet(*resnet_spec[50])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T09:40:49.274069Z","iopub.execute_input":"2025-02-23T09:40:49.274474Z","iopub.status.idle":"2025-02-23T09:40:49.370683Z","shell.execute_reply.started":"2025-02-23T09:40:49.274443Z","shell.execute_reply":"2025-02-23T09:40:49.368819Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport json\n\n# Load JSON file\nfile_path = \"/kaggle/input/coco-2017-dataset/coco2017/annotations/person_keypoints_train2017.json\"  \nwith open(file_path, \"r\") as file:\n    data = json.load(file) \nprint(\"Top-level keys in the JSON file:\")\nfor key in data.keys():\n    print(key)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T11:08:15.645773Z","iopub.execute_input":"2025-02-23T11:08:15.646167Z","iopub.status.idle":"2025-02-23T11:08:28.357668Z","shell.execute_reply.started":"2025-02-23T11:08:15.646134Z","shell.execute_reply":"2025-02-23T11:08:28.355997Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimages_df = pd.DataFrame(data[\"images\"])  # Convert \"images\" key to a DataFrame\nannotations_df = pd.DataFrame(data[\"annotations\"])  # Convert \"annotations\" key to a DataFrame\nimages_df[\"image_id\"] = images_df[\"file_name\"].str.replace(\".jpg\", \"\", regex=False).astype(int)\n# Display first few rows\nprint(\"Images DataFrame:\")\nprint(images_df.head())\n\nprint(\"\\nAnnotations DataFrame:\")\nprint(annotations_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T11:08:28.360186Z","iopub.execute_input":"2025-02-23T11:08:28.360605Z","iopub.status.idle":"2025-02-23T11:08:30.624919Z","shell.execute_reply.started":"2025-02-23T11:08:28.360570Z","shell.execute_reply":"2025-02-23T11:08:30.623278Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T10:29:33.494810Z","iopub.execute_input":"2025-02-23T10:29:33.495296Z","iopub.status.idle":"2025-02-23T10:29:36.599185Z","shell.execute_reply.started":"2025-02-23T10:29:33.495261Z","shell.execute_reply":"2025-02-23T10:29:36.597467Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\n# Create output directories if they don't exist\noutput_dir = \"train_images\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Global unique ID for saved images\nglobal_id = 1  \n\n# Dataframes to store image metadata\nimage_data = []\nkeypoint_data = []\npbar=tqdm(range(len(images_df)))\nfor idx in pbar:\n    # idx = random.randint(1, len(images_df) - 1)\n\n    # Get annotations for the selected image\n    figures = annotations_df[annotations_df[\"image_id\"] == images_df[\"image_id\"].iloc[idx]]\n    if len(figures) == 0:\n        continue  # Skip if no annotations\n\n    # Get image name and load it\n    name = images_df[\"file_name\"][images_df[\"image_id\"] == images_df[\"image_id\"].iloc[idx]]\n    image_name = name.iloc[0]\n    img = Image.open(f\"/kaggle/input/coco-2017-dataset/coco2017/train2017/{image_name}\")\n\n    height = images_df[\"height\"].iloc[idx]\n    width = images_df[\"width\"].iloc[idx]\n\n    for (x, y, w, h), key in zip(figures[\"bbox\"], figures[\"keypoints\"]):\n        # x1, y1 = [], []\n        if w==0 or h==0:\n            c\n        count = 0\n        keypoints = []\n\n        for j in range(2, len(key), 3):  # Process keypoints (x, y, visibility)\n            kx = round((key[j-2] - x) / w * 480)\n            ky = round((key[j-1] - y) / h * 480)\n            row = [0, 0, 0]\n\n            if key[j] > 0 and 0 <= kx <= 480 and 0 <= ky <= 480:  # If keypoint is visible\n                count += 1\n                \n                # x1.append(kx)\n                # y1.append(ky)\n                keypoints.extend([kx, ky, 1])  # Store valid keypoint\n            \n            else:\n                keypoints.extend(row)  # Keypoint not visible\n\n        # Skip if there are no valid keypoints\n        if count ==0:\n            continue\n\n        # Generate unique image filename\n        new_img_name = f\"{global_id}.jpg\"\n        global_id += 1  # Increment unique ID\n        pbar.set_postfix(status=f\"Step {global_id}\")\n        # Crop and resize image\n        cropped_image = img.crop((x, y, x + w, y + h)).resize((480, 480))\n\n        # Save cropped image\n        cropped_image.save(os.path.join(output_dir, new_img_name))\n\n        # Store metadata in dataframes\n        image_data.append({\"image_id\": new_img_name})\n        keypoint_data.append({\"image_id\": new_img_name, \"keypoints\": keypoints})\n\n# Convert lists to DataFrames\nimage_df = pd.DataFrame(image_data)\nkeypoint_df = pd.DataFrame(keypoint_data)\n\n# Save DataFrames as CSV\nimage_df.to_csv(\"train_image_data.csv\", index=False)\nkeypoint_df.to_csv(\"train_keypoint_data.csv\", index=False)\n\nprint(\"Processing complete. Images and metadata saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T11:08:30.627138Z","iopub.execute_input":"2025-02-23T11:08:30.627526Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r \"filename.zip\" \"/kaggle/working\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:51:00.649429Z","iopub.execute_input":"2025-02-23T17:51:00.650003Z","iopub.status.idle":"2025-02-23T17:51:00.657725Z","shell.execute_reply.started":"2025-02-23T17:51:00.649958Z","shell.execute_reply":"2025-02-23T17:51:00.656483Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Replace 'your_filename.ext' with the actual file name\nFileLink(r'filename.zip')","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null}]}